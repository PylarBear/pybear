# Author:
#         Bill Sousa
#
# License: BSD 3 clause
#



from typing import (
    Optional,
    Sequence,
    Self
)
from ._type_aliases import (
    OverallStatisticsType,
    StartsWithFrequencyType,
    CharacterFrequencyType,
    WordFrequencyType,
    LongestWordsType,
    ShortestWordsType
)

from copy import deepcopy

import numpy as np

from ._validation._words import _val_words
from ._validation._overall_statistics_dict import _val_overall_statistics_dict
from ._validation._uniques import _val_uniques
from ._validation._word_frequency import _val_word_frequency

from ._partial_fit._build_current_overall_statistics import \
    _build_current_overall_statistics
from ._partial_fit._merge_overall_statistics import _merge_overall_statistics
from ._partial_fit._build_current_word_frequency import \
    _build_current_word_frequency
from ._partial_fit._merge_word_frequency import _merge_word_frequency

from ....base import (
    GetParamsMixin,
    ReprMixin,
    SetParamsMixin,
    check_is_fitted,
    validate_data
)



class TextStatistics(
    GetParamsMixin,
    ReprMixin,
    SetParamsMixin
):


    def __init__(
        self,
        case_sensitive: Optional[bool] = False,
        ignore_non_latin_characters: Optional[bool] = True
    ) -> None:

        """
        pizza finalize this.
        Generate statistics about a list of words. Returns
        nothing. Statistics include
        - size
        - uniques count
        - average length and standard deviation
        - max word length
        - min word length
        - 'starts with' frequency
        - letter frequency
        - top word frequencies
        - top longest words


        Parameters
        ----------
        case_sensitive:
            Optional[bool], default = False - whether to handle all
            letters as if they are the same case. When True, keep
            separate statistics for upper and lower-case letters; when
            False, ignore the case.
        ignore_non_latin_characters:
            Optional[bool], default = True, whether to keep statistics
            for non-Latin characters.



        Return
        ------
        -
            None

        """

        self.case_sensitive = case_sensitive
        self.ignore_non_latin_characters = ignore_non_latin_characters


    def __pybear_is_fitted__(self):

        """
        If an estimator/transformer does not set any attributes with a
        trailing underscore, it can define a '__pybear_is_fitted__' method
        returning a boolean to specify if the estimator/transformer is
        fitted or not.

        """

        # must have this because there are no trailing-underscore attrs
        # generated by {partial_}fit(). all the trailing-underscore attrs
        # are accessed via @property.
        return hasattr(self, '_overall_statistics')


    # overall_statistics_ -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
    @property
    def overall_statistics_(self) -> OverallStatisticsType:

        """
        A dictionary that holds information about all the words fitted
        on the TextStatistics instance.

        """

        check_is_fitted(self)

        return self._overall_statistics


    @overall_statistics_.setter
    def overall_statistics_(self, value):
        raise AttributeError(f'overall_statistics_ attribute is read-only')


    def print_overall_statistics(self):

        """Print overall statistics to screen."""

        _lp = 5  # left pad
        _rp = 15  # right pad

        print(f'\nSTATISTICS:')
        for _description, _value in self.overall_statistics_.items():
            print(f' ' * _lp + str(_description).ljust(2 * _rp), _value)

    # END overall_statistics_ -- -- -- -- -- -- -- -- -- -- -- -- -- --

    # uniques_ -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
    @property
    def uniques_(self):

        check_is_fitted(self)

        return self._uniques


    @uniques_.setter
    def uniques_(self, value):
        raise AttributeError(f'overall_statistics_ attribute is read-only')

    # END uniques_ -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --

    # starts_with_frequency_ -- -- -- -- -- -- -- -- -- -- -- -- -- --
    @property
    def starts_with_frequency_(self) -> StartsWithFrequencyType:

        check_is_fitted(self)

        # dictionary for holding frequency counts of letters
        LETTER_DICT = {
            'a':0, 'b':0, 'c':0, 'd':0, 'e':0, 'f':0, 'g':0, 'h':0, 'i':0,
            'j':0, 'k':0, 'l':0, 'm':0, 'n':0, 'o':0, 'p':0, 'q':0, 'r':0,
            's':0, 't':0, 'u':0, 'v':0, 'w':0, 'x':0, 'y':0, 'z':0, 'other':0
        }

        # "STARTS WITH" FREQ ** * ** * ** * ** * ** * ** * ** * ** * ** * **
        START_DICT = deepcopy(LETTER_DICT)
        for word in WORDS:
            try:
                START_DICT[word[0].lower()] += 1
            except:
                START_DICT['other'] += 1

        KEYS = np.fromiter(START_DICT.keys(), dtype='<U5')
        # DONT USE np.int8 OR 16! NUMBERS TOO BIG!
        VALUES = np.fromiter(START_DICT.values(), dtype=np.int32)
        MASK = np.flip(np.argsort(VALUES))
        SORTED_DICT = {k:v for k,v in zip(KEYS[MASK], VALUES[MASK])}
        SORTED_KEYS = np.fromiter(SORTED_DICT.keys(), dtype='<U5')

        # CHANGE KEYS FOR EASY PRINT
        for new_key in range(26):
            START_DICT[new_key] = START_DICT.pop(KEYS[new_key])
            SORTED_DICT[new_key] = SORTED_DICT.pop(SORTED_KEYS[new_key])

        del VALUES, MASK


        print(f'\n"STARTS WITH" FREQUENCY:')

        for i in range(26):
            print(_lp*' ' + f'{KEYS[i].upper()}:'.ljust(_rp), end='')
            print(f'{START_DICT[i]}'.ljust(2*_rp), end='')
            print(_lp*' ' + f'{SORTED_KEYS[i].upper()}:'.ljust(_rp), end='')
            print(f'{SORTED_DICT[i]}')

        del START_DICT, KEYS, SORTED_DICT, SORTED_KEYS
        # END "STARTS WITH" FREQ ** * ** * ** * ** * ** * ** * ** * ** * ** *


    @starts_with_frequency_.setter
    def starts_with_frequency_(self, value):
        raise AttributeError(f'starts_with_frequency_ attribute is read-only')


    @property
    def character_frequency_(self) -> CharacterFrequencyType:

        check_is_fitted(self)

        # LETTER FREQ ** * ** * ** * ** * ** * ** * ** * ** * ** * ** * ** *

        LETTER_DICT = {
            'a':0, 'b':0, 'c':0, 'd':0, 'e':0, 'f':0, 'g':0, 'h':0, 'i':0,
            'j':0, 'k':0, 'l':0, 'm':0, 'n':0, 'o':0, 'p':0, 'q':0, 'r':0,
            's':0, 't':0, 'u':0, 'v':0, 'w':0, 'x':0, 'y':0, 'z':0, 'other':0
        }

        FREQ_DICT = deepcopy(LETTER_DICT)
        for word in WORDS:
            for letter in word:
                try: FREQ_DICT[letter.lower()] += 1
                except: FREQ_DICT['other'] += 1

        KEYS = np.fromiter(FREQ_DICT.keys(), dtype='<U5')
        # DONT USE np.int8 OR 16! NUMBERS TOO BIG!
        VALUES = np.fromiter(FREQ_DICT.values(), dtype=np.int32)
        MASK = np.flip(np.argsort(VALUES))
        SORTED_DICT = {k:v for k,v in zip(KEYS[MASK], VALUES[MASK])}
        SORTED_KEYS = np.fromiter(SORTED_DICT.keys(), dtype='<U5')

        # CHANGE KEYS FOR EASY PRINT
        for new_key in range(27):
            FREQ_DICT[new_key] = FREQ_DICT.pop(KEYS[new_key])
            SORTED_DICT[new_key] = SORTED_DICT.pop(SORTED_KEYS[new_key])

        del VALUES, MASK

        print(f'\nOVERALL LETTER FREQUENCY:')

        for i in range(26):
            print(_lp*' ' + f'{KEYS[i].upper()}:'.ljust(_rp), end='')
            print(f'{FREQ_DICT[i]}'.ljust(2*_rp), end='')
            print(_lp*' ' + f'{SORTED_KEYS[i].upper()}:'.ljust(_rp), end='')
            print(f'{SORTED_DICT[i]}')

        del FREQ_DICT, KEYS, SORTED_DICT, SORTED_KEYS
        # END LETTER FREQ ** * ** * ** * ** * ** * ** * ** * ** * ** * ** *


    @character_frequency_.setter
    def character_frequency_(self, value):
        raise AttributeError(f'character_frequency_ attribute is read-only')


    # word_frequency ** * ** * ** * ** * ** * ** * ** * ** * ** * ** *
    @property
    def word_frequency_(self) -> WordFrequencyType:

        check_is_fitted(self)

        return self._word_frequency


    @word_frequency_.setter
    def word_frequency_(self, value):
        raise AttributeError(f'word_frequency_ attribute is read-only')


    def print_word_frequency(self):

        check_is_fitted(self)

        n = min(20, len(_UNIQUES))
        print(f'\n TOP {n} WORD FREQUENCY:')
        MASK = np.flip(np.argsort(_COUNTS))[:n]

        print(_lp*' ' + (f'WORD').ljust(2*_rp) + f'FREQUENCY')
        for i in range(n):
            print(_lp * ' ' + f'{_UNIQUES[..., MASK][i]}'.ljust(2*_rp), end='')
            print(f'{_COUNTS[..., MASK][i]}')

        del _UNIQUES, _COUNTS, _LENS, _lp, _rp

    # END word_frequency ** * ** * ** * ** * ** * ** * ** * ** * ** * **


    @property
    def longest_words_(self) -> LongestWordsType:

        check_is_fitted(self)

        # TOP LONGEST WORDS ** * ** * ** * ** * ** * ** * ** * ** * ** * ** *
        n = min(20, len(_UNIQUES))
        print(f'\nTOP {n} LONGEST WORDS:')

        _LENS = np.fromiter(map(len, _UNIQUES), dtype=np.int8)

        MASK = np.flip(np.argsort(_LENS))
        LONGEST_WORDS = _UNIQUES[MASK][:n]
        _LENS = _LENS[MASK][:n]
        del MASK

        print(_lp*' ' + f'WORD'.ljust(3*_rp) + f'LENGTH')
        for i in range(n):
            print(_lp*' ' + f'{(LONGEST_WORDS[i])}'.ljust(3*_rp), end='')
            print(f'{_LENS[i]}')

        del LONGEST_WORDS
        # END TOP LONGEST WORDS ** * ** * ** * ** * ** * ** * ** * ** * ** *


    @longest_words_.setter
    def longest_words_(self, value):
        raise AttributeError(f'longest_words_ attribute is read-only')


    @property
    def shortest_words_(self) -> ShortestWordsType:

        check_is_fitted(self)

        pass


    @shortest_words_.setter
    def shortest_words_(self, value):
        raise AttributeError(f'shortest_words_ attribute is read-only')


    def _reset(self):

        pass
        # pizza what to delete?


    def _lowercase_dict(self):
        CHARS = list('abcdefghijklmnopqrstuvwxyz')  
        return dict((zip(CHARS, [0 for _ in range(26)])))


    def _uppercase_dict(self):
        CHARS = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')
        return dict((zip(CHARS, [0 for _ in range(26)])))


    def _number_dict(self):
        return {}


    def _other_dict(self):
        return {
            'other':0
        }


    def partial_fit(self, WORDS: Sequence[str]) -> Self:

        """
        Batch-wise accumulation of statistics.


        Parameters
        ----------
        WORDS:
            Sequence[str] - a single list-like vector of words to report
            statistics for, cannot be empty. Words do not need to be in
            the Lexicon. Individual words cannot have spaces and must be
            under 30 characters in length.


        Return
        ------
        -
            self


        """

        # validation ** * ** * ** * ** * ** * ** * ** * ** * ** * ** * **

        validate_data(
            WORDS,
            copy_X=False,
            cast_to_ndarray=False,
            accept_sparse=None,
            dtype='any',
            require_all_finite=False,
            cast_inf_to_nan=False,
            standardize_nan=False,
            allowed_dimensionality=(1,),
            ensure_2d=False,
            order='C',
            ensure_min_features=1,
            ensure_max_features=1,
            ensure_min_samples=1,
            sample_check=None
        )

        _val_words(WORDS)

        # END validation ** * ** * ** * ** * ** * ** * ** * ** * ** * **

        # uniques -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
        # pizza make a decision on the format of UNIQUES
        # pizza probably turn this into its own module, something like _merge_uniques
        if not hasattr(self, '_uniques'):
            if self.case_sensitive:
                self._uniques = set(WORDS)
            elif not self.case_sensitive:
                self._uniques = set(map(str.upper, WORDS))
        else:
            if self.case_sensitive:
                self._uniques = set(self._uniques).union(set(WORDS))
            elif not self.case_sensitive:
                self._uniques = set(
                    map(str.upper, self._uniques)
                ).union(map(str.upper, WORDS))

        _val_uniques(self._uniques)
        # END uniques -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --

        # overall_statistics_ -- -- -- -- -- -- -- -- -- -- -- -- -- --
        _current_overall_statistics = \
            _build_current_overall_statistics(
                WORDS,
                case_sensitive=self.case_sensitive
            )

        self._overall_statistics = _merge_overall_statistics(
            _current_overall_statistics,
            getattr(self, '_overall_statistics', {}),
            len(self._uniques)
        )

        del _current_overall_statistics

        _val_overall_statistics_dict(self._overall_statistics)
        # END overall_statistics_ -- -- -- -- -- -- -- -- -- -- -- -- --

        # pizza
        self._starts_with_frequency = _merge_startswith_frequency_dict(

        )

        # pizza
        self._character_frequency = _merge_character_frequency_dict(

        )

        # word_frequency_ -- -- -- -- -- -- -- -- -- -- -- -- -- -- --

        _current_word_frequency = \
            _build_current_word_frequency(
                WORDS,
                case_sensitive=self.case_sensitive
            )

        self._word_frequency = _merge_word_frequency(
            _current_word_frequency,
            getattr(self, '_word_frequency', {})
        )

        del _current_word_frequency

        _val_word_frequency(self._word_frequency)
        # END word_frequency_ -- -- -- -- -- -- -- -- -- -- -- -- -- --


    def fit(self, WORDS: Sequence[str]):

        """
        Get statistics for one sequence of words.


        Parameters
        ----------
        WORDS:
            Sequence[str] - a single list-like vector of words to report
            statistics for, cannot be empty. Words do not need to be in
            the Lexicon. Individual words cannot have spaces and must be
            under 30 characters in length.


        Return
        ------
        -
            self


        """

        self._reset()

        return self.partial_fit(WORDS)














