{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f53e4-635a-45f3-a8d9-3bf364430f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split as sklearn_train_test_split\n",
    "from sklearn.datasets import make_classification as sklearn_make_classification\n",
    "from sklearn.model_selection import GridSearchCV as sklearn_GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression as sklearn_Logistic\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import dask.array as da\n",
    "import dask.dataframe as ddf\n",
    "from dask_ml.model_selection import train_test_split as dask_train_test_split\n",
    "from dask_ml.datasets import make_classification as dask_make_classification\n",
    "from dask_ml.model_selection import GridSearchCV as dask_GridSearchCV\n",
    "from dask_ml.linear_model import LogisticRegression as dask_Logistic\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%%time\n",
    "\n",
    "_rows = 2_000_000\n",
    "_columns = 10\n",
    "COLUMNS = list(string.ascii_lowercase[:_columns])\n",
    "\n",
    "sk_np_X = np.random.randint(0,10,(_rows,_columns))\n",
    "sk_np_y = np.random.randint(0,2,(_rows,))\n",
    "\n",
    "sk_df_X = pd.DataFrame(data=sk_np_X, columns=COLUMNS)\n",
    "sk_df_y = pd.DataFrame(data=sk_np_y, columns=['Y'])\n",
    "\n",
    "da_da_X = da.random.randint(0,10,(_rows,_columns)).rechunk((_rows//10, _columns))\n",
    "da_da_y = da.random.randint(0,2,(_rows,)).rechunk((_rows//10,))\n",
    "\n",
    "da_df_X = ddf.from_array(da_da_X, columns=COLUMNS, chunksize=(_rows//10,))\n",
    "da_df_y = ddf.from_array(da_da_y, columns=['Y'], chunksize=(_rows//10,))\n",
    "\n",
    "\n",
    "\n",
    "# BEARS LOOK AT NP ARRAYS ######################################################\n",
    "\n",
    "%%time\n",
    "sk_np_X1, sk_np_X_test, sk_np_y1, sk_np_y_test = sklearn_train_test_split(sk_np_X, sk_np_y, test_size=0.2)\n",
    "sk_np_X_train, sk_np_X_val, sk_np_y_train, sk_np_y_val = sklearn_train_test_split(sk_np_X1, sk_np_y1, test_size=0.25)\n",
    "\n",
    "%%time\n",
    "sk_logistic_np = sklearn_Logistic(max_iter=10_000, tol=1e-6)\n",
    "\n",
    "# VERIFY DTYPES\n",
    "sk_np_X_train\n",
    "\n",
    "sk_np_y_train\n",
    "\n",
    "%%time\n",
    "sk_logistic_np.fit(sk_np_X_train, sk_np_y_train)\n",
    "\n",
    "# END BEARS LOOK AT NP ARRAYS ######################################################\n",
    "\n",
    "\n",
    "\n",
    "### BEAR TRIES TO SPEED UP DASK ARRAYS ###############################################################################\n",
    "\n",
    "%%time\n",
    "da_da_X1, da_da_X_test, da_da_y1, da_y_test = dask_train_test_split(da_da_X, da_da_y, test_size=0.2)\n",
    "da_da_X_train, da_da_X_val, da_da_y_train, da_da_y_val = dask_train_test_split(da_da_X1, da_da_y1, test_size=0.25)\n",
    "\n",
    "%%time\n",
    "da_da_X_train = da_da_X_train.rechunk(da_da_X_train.shape)\n",
    "da_da_y_train = da_da_y_train.rechunk(da_da_y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "%%time\n",
    "da_logistic_da = dask_Logistic(max_iter=10_000, tol=1e-6)\n",
    "\n",
    "# VERIFY DTYPES\n",
    "da_da_X_train\n",
    "\n",
    "da_da_y_train\n",
    "\n",
    "%%time\n",
    "da_logistic_da.fit(da_da_X_train, da_da_y_train)\n",
    "\n",
    "### END BEAR TRIES TO SPEED UP DASK ARRAYS ###########################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# BEARS LOOK AT SK DATAFRAMES ######################################################################################\n",
    "\n",
    "sk_df_X = pd.DataFrame(data=np.random.randint(0,10,(_rows,_columns)), columns=COLUMNS)\n",
    "sk_df_y = pd.DataFrame(data=np.random.randint(0,2,(_rows,)), columns=['Y'])\n",
    "\n",
    "%%time\n",
    "sk_df_X1, sk_df_X_test, sk_df_y1, sk_df_y_test = sklearn_train_test_split(sk_df_X, sk_df_y, test_size=0.2)\n",
    "sk_df_X_train, sk_df_X_val, sk_df_y_train, sk_df_y_val = sklearn_train_test_split(sk_df_X1, sk_df_y1, test_size=0.25)\n",
    "\n",
    "%%time\n",
    "sk_logistic_df = sklearn_Logistic(max_iter=10_000, tol=1e-6)\n",
    "\n",
    "# VERIFY DTYPES\n",
    "sk_df_X_train\n",
    "\n",
    "sk_df_y_train\n",
    "\n",
    "%%time\n",
    "sk_logistic_df.fit(sk_df_X_train, sk_df_y_train)\n",
    "\n",
    "# BEARS LOOK AT SK DATAFRAMES ######################################################################################\n",
    "\n",
    "\n",
    "\n",
    "### BEAR TRIES TO SPEED UP DASK DATAFRAMES ###############################################################################\n",
    "\n",
    "# dask_Logistic CANT TAKE DDFs\n",
    "\n",
    "### END BEAR TRIES TO SPEED UP DASK DATAFRAMES ###############################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = np.random.randint(0,10,(500,5))\n",
    "y = np.random.randint(0,2,(500,))\n",
    "\n",
    "tater = sklearn_GridSearchCV(\n",
    "                                estimator=sklearn_Logistic(),\n",
    "                                param_grid={'C':[100]},\n",
    "                                scoring=['balanced_accuracy','accuracy'],\n",
    "                                refit='balanced_accuracy',\n",
    "                                return_train_score=True\n",
    ")\n",
    "\n",
    "tater.fit(X,y)\n",
    "\n",
    "tater.predict_proba(X)\n",
    "\n",
    "tater.score(X, y)\n",
    "\n",
    "# SCORE BY balanced_accuracy_score\n",
    "balanced_accuracy_score(y, tater.predict(X))\n",
    "\n",
    "DUM = pd.DataFrame(tater.cv_results_)\n",
    "for _ in DUM:\n",
    "    print(f\"{_}\".ljust(30) + f\"{DUM[_].to_frame().to_numpy()[0][0]}\")\n",
    "\n",
    "  data=[[0.5 , 0.5 ],\n",
    "        [0.25, 0.25],\n",
    "        [0.5 , 0.5 ],\n",
    "        [0.25, 0.25],\n",
    "        [0.25, 0.25]],\n",
    "\n",
    "\n",
    "\n",
    "new_tater = tater.set_params(estimator__C=10)\n",
    "\n",
    "new_tater.predict_proba(X)\n",
    "\n",
    "new_tater.score(X, y)\n",
    "\n",
    "\n",
    "\n",
    "from GridSearchThresholdCV import GridSearchThresholdCV\n",
    "\n",
    "test_gstcv = GridSearchThresholdCV(\n",
    "                                    estimator=sklearn_Logistic(),\n",
    "                                    param_grid={'C':[100]},\n",
    "                                    scoring=['balanced_accuracy','accuracy'],\n",
    "                                    refit='balanced_accuracy',\n",
    "                                    thresholds=np.linspace(0,1,21),\n",
    "                                    return_train_score=True\n",
    ")\n",
    "\n",
    "test_gstcv.fit(X,y)\n",
    "\n",
    "test_gstcv.predict_proba(X)\n",
    "\n",
    "test_gstcv.score(X,y)\n",
    "\n",
    "test_gstcv.best_index_\n",
    "\n",
    "test_gstcv.best_threshold_\n",
    "\n",
    "# DUMP_DF = pd.DataFrame(test_gstcv.cv_results_)\n",
    "# DUMP_DF.to_csv(r'/home/bear/Desktop/GSTCV_TEST_CV_RESULTS.ods')\n",
    "\n",
    "tftssm = test_gstcv._TEST_FOLD_x_THRESHOLD_x_SCORER__SCORE_MATRIX\n",
    "tftssm[:, 7, :]\n",
    "\n",
    "tftssm.mean(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_test_gstcv = test_gstcv.set_params(estimator__C=10)\n",
    "\n",
    "# for _thresh in np.linspace(0,1,21):\n",
    "#     new_test_gstcv.best_threshold_ = _thresh\n",
    "#     print(f'{_thresh}: {new_test_gstcv.score(X,y)}')\n",
    "\n",
    "new_test_gstcv.best_threshold_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90ae3a-08c7-499f-86c0-d20fa5f4c1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a44ef2-915d-48b2-ad4e-505abcaefbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cdc915-c2bb-4711-ae20-0a8635e31409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62534614-a9d3-491e-bd40-e52a0a08b83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb41858-c50a-4ec1-be57-91dd08370517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be6ca7-a6c9-4d39-842b-9d460ef6f44b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6227fd7-3806-47f5-b06c-8a1ca354d113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06924a4-def5-4fcd-b86e-23953c384ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1b540-eab0-431c-b677-775a97fa263c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203374e-8386-4cbf-baf4-9f333cab7eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b82ab7c-8c43-4a3d-806a-41d389f96537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b3b2e7-eff6-4773-b44d-6964e6857410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f1ee7f-1f4f-4f47-ad1d-1d46375a1c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0316af3-ab0b-4e52-85a1-bf0456a058a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
