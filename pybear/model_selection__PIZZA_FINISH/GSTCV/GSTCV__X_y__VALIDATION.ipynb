{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e62600-3571-4fc1-8367-bded9a7a0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os, base64, io, time\n",
    "import scipy.sparse as ss\n",
    "import functools\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split as sklearn_train_test_split\n",
    "from sklearn.datasets import make_classification as sklearn_make_classification\n",
    "from sklearn.model_selection import GridSearchCV as sklearn_GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression as sklearn_Logistic\n",
    "\n",
    "import dask.array as da\n",
    "import dask.dataframe as ddf\n",
    "from dask_ml.model_selection import train_test_split as dask_train_test_split\n",
    "from dask_ml.datasets import make_classification as dask_make_classification\n",
    "from dask_ml.model_selection import GridSearchCV as dask_GridSearchCV\n",
    "from dask_ml.linear_model import LogisticRegression as dask_Logistic\n",
    "\n",
    "from GridSearchThresholdCV import GridSearchThresholdCV as GSTCV\n",
    "\n",
    "\n",
    "\n",
    "# X, y\n",
    "# score(X, y)\n",
    "\n",
    "\n",
    "# X\n",
    "# decision_function(X)\n",
    "# inverse_transform(Xt)\n",
    "# predict(X)\n",
    "# predict_log_proba(X)\n",
    "# predict_proba(X)\n",
    "# score_samples(X)\n",
    "# transform(X)\n",
    "\n",
    "\n",
    "\n",
    "_rows, _cols = 1000, 10\n",
    "_bad_cols = 2*_cols\n",
    "GOOD_COLUMNS = list(string.ascii_lowercase[:_cols])\n",
    "BAD_COLUMNS = list(string.ascii_lowercase[:_bad_cols])\n",
    "\n",
    "\n",
    "good_np_X, good_np_y = sklearn_make_classification(n_samples=_rows, n_features=_cols, n_informative=_cols, n_redundant=0)\n",
    "good_da_X, good_da_y = da.array(good_np_X), da.array(good_np_y)\n",
    "\n",
    "good_pd_X, good_pd_y = pd.DataFrame(good_np_X, columns=GOOD_COLUMNS), pd.DataFrame(good_np_y, columns=['y'])\n",
    "good_ddf_X, good_ddf_y = ddf.from_pandas(good_pd_X, chunksize=_rows//10), ddf.from_pandas(good_pd_y, chunksize=_rows//10)\n",
    "\n",
    "\n",
    "bad_np_X, bad_features_np_y = sklearn_make_classification(n_samples=_rows, n_features=_bad_cols, n_informative=_bad_cols, n_redundant=0)\n",
    "bad_features_np_y = np.vstack((bad_features_np_y, bad_features_np_y)).reshape((-1,2))\n",
    "bad_da_X, bad_features_da_y = da.array(bad_np_X), da.array(bad_features_np_y)\n",
    "\n",
    "bad_pd_X, bad_features_pd_y = pd.DataFrame(bad_np_X, columns=BAD_COLUMNS), pd.DataFrame(bad_features_np_y, columns=['y1','y2'])\n",
    "bad_ddf_X, bad_features_ddf_y = ddf.from_pandas(bad_pd_X, chunksize=_rows//10), ddf.from_pandas(bad_features_pd_y, chunksize=_rows//10)\n",
    "\n",
    "\n",
    "bad_classes_np_y = np.random.randint(0,3,_rows)\n",
    "bad_classes_da_y = da.array(bad_classes_np_y)\n",
    "bad_classes_pd_y = pd.DataFrame(bad_classes_np_y, columns=['y'])\n",
    "bad_classes_ddf_y = ddf.from_pandas(bad_classes_pd_y, chunksize=_rows//10)\n",
    "\n",
    "\n",
    "\n",
    "GOOD_OR_BAD_X = ['good_X', 'bad_X']\n",
    "GOOD_OR_BAD_y = ['good_y', 'bad_features_y', 'bad_classes_y']\n",
    "DTYPES = ['array', 'dataframe']\n",
    "TYPES = ['sklearn', 'dask', 'gstcv_sklearn', 'gstcv_dask']\n",
    "\n",
    "METHOD_NAMES = [\n",
    "                'n_features_in_',\n",
    "                'feature_names_in_',\n",
    "                'classes_',\n",
    "\n",
    "    \n",
    "                'decision_function',\n",
    "                'inverse_transform',\n",
    "                'predict',\n",
    "                'predict_log_proba',\n",
    "                'predict_proba',\n",
    "                'score_samples',\n",
    "                'transform',\n",
    "\n",
    "                'score'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "__scoring = ['balanced_accuracy', 'accuracy']     # 'balanced_accuracy'\n",
    "__refit = 'balanced_accuracy'\n",
    "\n",
    "\n",
    "SklearnLogistic = sklearn_Logistic(    \n",
    "                                    penalty='l2',\n",
    "                                    dual=False,\n",
    "                                    tol=1e-6,\n",
    "                                    # C=1.0,\n",
    "                                    fit_intercept=False,\n",
    "                                    intercept_scaling=1,\n",
    "                                    class_weight=None,\n",
    "                                    random_state=None,\n",
    "                                    solver='lbfgs',\n",
    "                                    max_iter=10000,\n",
    "                                    multi_class='auto',\n",
    "                                    verbose=0,\n",
    "                                    warm_start=False,\n",
    "                                    n_jobs=-1,\n",
    "                                    l1_ratio=None,\n",
    ")\n",
    "    \n",
    "\n",
    "DaskLogistic = dask_Logistic(\n",
    "                                    penalty='l2',\n",
    "                                    dual=False,\n",
    "                                    tol=1e-6,\n",
    "                                    # C=1.0,\n",
    "                                    fit_intercept=False,\n",
    "                                    intercept_scaling=1.0,\n",
    "                                    class_weight=None,\n",
    "                                    random_state=None,\n",
    "                                    solver='lbfgs',\n",
    "                                    max_iter=10000,\n",
    "                                    multi_class='ovr',\n",
    "                                    verbose=0,\n",
    "                                    warm_start=False,\n",
    "                                    n_jobs=-1,\n",
    "                                    solver_kwargs=None,\n",
    ")\n",
    "\n",
    "def init_gscv(_sk_est, _da_est, _type):\n",
    "    \n",
    "    _param_grid = {'C': np.logspace(-3,3,7)}\n",
    "\n",
    "    if _type == 'sklearn':\n",
    "        _gscv = sklearn_GridSearchCV(\n",
    "                                      estimator=_sk_est,\n",
    "                                      param_grid=_param_grid,\n",
    "                                      scoring=__scoring,\n",
    "                                      refit=__refit,\n",
    "                                      cv=5,\n",
    "                                      error_score=np.nan,\n",
    "                                      return_train_score=True,\n",
    "                                      n_jobs=-1\n",
    "        )\n",
    "    \n",
    "    elif _type == 'dask':\n",
    "        _gscv = dask_GridSearchCV(\n",
    "                                      estimator=_da_est,\n",
    "                                      param_grid=_param_grid,\n",
    "                                      scoring=__scoring,\n",
    "                                      refit=__refit,\n",
    "                                      cv=5,\n",
    "                                      error_score=np.nan,\n",
    "                                      return_train_score=True,\n",
    "                                      n_jobs=-1\n",
    "        )\n",
    "\n",
    "    elif _type == 'gstcv_sklearn':\n",
    "        _gscv = GSTCV(\n",
    "                                      estimator=_sk_est,\n",
    "                                      param_grid=_param_grid,\n",
    "                                      scoring=__scoring,\n",
    "                                      refit=__refit,\n",
    "                                      cv=5,\n",
    "                                      error_score=np.nan,            \n",
    "                                      return_train_score=True,\n",
    "                                      n_jobs=-1\n",
    "        \n",
    "        )\n",
    "        \n",
    "    elif _type == 'gstcv_dask':\n",
    "        _gscv = GSTCV(\n",
    "                                      estimator=_da_est,\n",
    "                                      param_grid=_param_grid,\n",
    "                                      scoring=__scoring,\n",
    "                                      refit=__refit,\n",
    "                                      cv=5,\n",
    "                                      error_score=np.nan,            \n",
    "                                      return_train_score=True,\n",
    "                                      n_jobs=-1\n",
    "        )\n",
    "    \n",
    "    return _gscv\n",
    "\n",
    "\n",
    "def key_handler(_trial, _METHOD_ARRAY_DICT):\n",
    "    if _trial not in _METHOD_ARRAY_DICT:\n",
    "        raise ValueError(f\"trying to modify key {_trial} in METHOD_ARRAY_DICT but key doesnt exist\")\n",
    "\n",
    "def method_output_try_handler(_trial, method_name, _method_output, _METHOD_ARRAY_DICT):\n",
    "    key_handler(_trial, _METHOD_ARRAY_DICT)\n",
    "    _METHOD_ARRAY_DICT[_trial].loc[method_name, 'OUTPUT'] = _method_output\n",
    "    return _METHOD_ARRAY_DICT\n",
    "\n",
    "def method_output_except_handler(_trial, method_name, _exc_info, _METHOD_ARRAY_DICT):\n",
    "    key_handler(_trial, _METHOD_ARRAY_DICT)\n",
    "    _METHOD_ARRAY_DICT[_trial].loc[method_name, 'OUTPUT'] = _exc_info\n",
    "    return _METHOD_ARRAY_DICT\n",
    "\n",
    "\n",
    "\n",
    "COMBINATIONS = [f'{c}_{b}_{a}' for c in GOOD_OR_BAD_X for b in DTYPES for a in TYPES]\n",
    "METHOD_ARRAY_DICT = {k:pd.DataFrame(index=METHOD_NAMES, columns=['OUTPUT'], dtype=object) for k in COMBINATIONS}\n",
    "\n",
    "ctr = 0\n",
    "for good_or_bad_x in GOOD_OR_BAD_X:\n",
    "    for _dtype in DTYPES:\n",
    "        for _gscv_type in TYPES:\n",
    "            \n",
    "            ctr += 1\n",
    "            trial = f'{good_or_bad_x}_{_dtype}_{_gscv_type}'\n",
    "\n",
    "            print(f'Running {ctr} of {len(COMBINATIONS)}... {trial}')\n",
    "            \n",
    "            test_cls = init_gscv(SklearnLogistic, DaskLogistic, _gscv_type)\n",
    "\n",
    "            if _dtype == 'array':\n",
    "                if 'dask' in _gscv_type:\n",
    "                    base_y = good_da_y\n",
    "                    base_X = good_da_X\n",
    "                    if 'good' in good_or_bad_x: _X = good_da_X\n",
    "                    elif 'bad' in good_or_bad_x: _X = bad_da_X\n",
    "                    else: raise Exception(f\"good_or_bad_x logic is failing\")\n",
    "                elif 'sklearn' in _gscv_type:\n",
    "                    base_y = good_np_y                      \n",
    "                    base_X = good_np_X\n",
    "                    if 'good' in good_or_bad_x: _X = good_np_X\n",
    "                    elif 'bad' in good_or_bad_x: _X = bad_np_X\n",
    "                    else: raise Exception(f\"good_or_bad_x logic is failing\")\n",
    "                else: raise Exception(f\"_gscv_type logic is failing\")\n",
    "            elif _dtype == 'dataframe':\n",
    "                if 'dask' in _gscv_type:\n",
    "                    base_y = good_np_y    #good_ddf_y  UNPREDICABLE BEHAVIOR PASSING y AS DF TO DASK GridSearcH\n",
    "                    base_X = good_ddf_X\n",
    "                    if 'good' in good_or_bad_x: _X = good_ddf_X\n",
    "                    elif 'bad' in good_or_bad_x: _X = bad_ddf_X\n",
    "                    else: raise Exception(f\"good_or_bad_x logic is failing\")\n",
    "                elif 'sklearn' in _gscv_type:\n",
    "                    base_y = good_pd_y\n",
    "                    base_X = good_pd_X\n",
    "                    if 'good' in good_or_bad_x: _X = good_pd_X\n",
    "                    elif 'bad' in good_or_bad_x: _X = bad_pd_X\n",
    "                    else: raise Exception(f\"good_or_bad_x logic is failing\")\n",
    "                else: raise Exception(f\"_gscv_type logic is failing\")\n",
    "            else: raise Exception(f\"_dtype logic is failing\")\n",
    "\n",
    "            \n",
    "            print(f'trial = {trial}')\n",
    "\n",
    "            try:\n",
    "                test_cls.fit(base_X, base_y)\n",
    "            except TypeError as e:\n",
    "                for _m in METHOD_NAMES:\n",
    "                    METHOD_ARRAY_DICT[trial].loc[_m, 'OUTPUT'] = e\n",
    "                del test_cls, base_X, base_y\n",
    "                continue \n",
    "            except Exception as e2:\n",
    "                print(f\"\\033[91mExcepted for a reason other than dask.dataframe into dask logistic TypeError\\033[0m\")\n",
    "                raise Exception(e2)\n",
    "\n",
    "\n",
    "            del base_X, base_y\n",
    "            \n",
    "            try:\n",
    "                __ = test_cls.decision_function(_X)\n",
    "                METHOD_ARRAY_DICT = method_output_try_handler(trial, 'decision_function', __, METHOD_ARRAY_DICT)\n",
    "            except:\n",
    "                METHOD_ARRAY_DICT = method_output_except_handler(trial, 'decision_function', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "\n",
    "            try:\n",
    "                __ = test_cls.inverse_transform(_X)\n",
    "                METHOD_ARRAY_DICT = method_output_try_handler(trial, 'inverse_transform', __, METHOD_ARRAY_DICT)\n",
    "            except:\n",
    "                METHOD_ARRAY_DICT = method_output_except_handler(trial, 'inverse_transform', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "\n",
    "            try:\n",
    "                __ = test_cls.predict(_X)\n",
    "                METHOD_ARRAY_DICT = method_output_try_handler(trial, 'predict', __, METHOD_ARRAY_DICT)\n",
    "            except:\n",
    "                METHOD_ARRAY_DICT = method_output_except_handler(trial, 'predict', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "\n",
    "            try:\n",
    "                __ = test_cls.predict_log_proba(_X)\n",
    "                METHOD_ARRAY_DICT = method_output_try_handler(trial, 'predict_log_proba', __, METHOD_ARRAY_DICT)\n",
    "            except:\n",
    "                METHOD_ARRAY_DICT = method_output_except_handler(trial, 'predict_log_proba', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "\n",
    "            try:\n",
    "                __ = test_cls.predict_proba(_X)\n",
    "                METHOD_ARRAY_DICT = method_output_try_handler(trial, 'predict_proba', __, METHOD_ARRAY_DICT)\n",
    "            except:\n",
    "                METHOD_ARRAY_DICT = method_output_except_handler(trial, 'predict_proba', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "\n",
    "            try:\n",
    "                __ = test_cls.score_samples(_X)\n",
    "                METHOD_ARRAY_DICT = method_output_try_handler(trial, 'score_samples', __, METHOD_ARRAY_DICT)\n",
    "            except:\n",
    "                METHOD_ARRAY_DICT = method_output_except_handler(trial, 'score_samples', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "\n",
    "            try:\n",
    "                __ = test_cls.transform(_X)\n",
    "                METHOD_ARRAY_DICT = method_output_try_handler(trial, 'transform', __, METHOD_ARRAY_DICT)\n",
    "            except:\n",
    "                METHOD_ARRAY_DICT = method_output_except_handler(trial, 'transform', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "\n",
    "\n",
    "\n",
    "            # REFERENCE ATTRS #################################################################################################\n",
    "            try:\n",
    "                __ = test_cls.n_features_in_\n",
    "                METHOD_ARRAY_DICT = method_output_try_handler(trial, 'n_features_in_', __, METHOD_ARRAY_DICT)\n",
    "            except:\n",
    "                METHOD_ARRAY_DICT = method_output_except_handler(trial, 'n_features_in_', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "            \n",
    "            try:\n",
    "                __ = test_cls.feature_names_in_\n",
    "                METHOD_ARRAY_DICT = method_output_try_handler(trial, 'feature_names_in_', __, METHOD_ARRAY_DICT)\n",
    "            except:\n",
    "                METHOD_ARRAY_DICT = method_output_except_handler(trial, 'feature_names_in_', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "\n",
    "            try:\n",
    "                __ = test_cls.classes_\n",
    "                METHOD_ARRAY_DICT = method_output_try_handler(trial, 'classes_', __, METHOD_ARRAY_DICT)\n",
    "            except:\n",
    "                METHOD_ARRAY_DICT = method_output_except_handler(trial, 'classes_', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "\n",
    "\n",
    "            del test_cls\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SINGLE_DF = pd.DataFrame(index=METHOD_NAMES, columns=list(METHOD_ARRAY_DICT.keys()), dtype='<U100').fillna('-')\n",
    "for _key, DATA_DF in METHOD_ARRAY_DICT.items():\n",
    "    SINGLE_DF.loc[:, _key] = DATA_DF.to_numpy().ravel()\n",
    "\n",
    "SINGLE_DF = SINGLE_DF.drop(['score'], inplace=False)\n",
    "\n",
    "if os.name =='posix': method_path = rf'/home/bear/Desktop/gscv_bad_X_comparison_dump__all_except_score.ods'\n",
    "elif os.name=='nt': method_path = rf'c:\\users\\bill\\desktop\\gscv_bad_X_comparison_dump__all_except_score.csv'\n",
    "\n",
    "SINGLE_DF.to_csv(method_path, index=True)\n",
    "\n",
    "def key_handler(_trial, _METHOD_ARRAY_DICT):\n",
    "    if _trial not in _METHOD_ARRAY_DICT:\n",
    "        raise ValueError(f\"trying to modify key {_trial} in METHOD_ARRAY_DICT but key doesnt exist\")\n",
    "\n",
    "def method_output_try_handler(_trial, method_name, _method_output, _METHOD_ARRAY_DICT):\n",
    "    key_handler(_trial, _METHOD_ARRAY_DICT)\n",
    "    _METHOD_ARRAY_DICT[_trial].loc[method_name, 'OUTPUT'] = _method_output\n",
    "    return _METHOD_ARRAY_DICT\n",
    "\n",
    "def method_output_except_handler(_trial, method_name, _exc_info, _METHOD_ARRAY_DICT):\n",
    "    key_handler(_trial, _METHOD_ARRAY_DICT)\n",
    "    _METHOD_ARRAY_DICT[_trial].loc[method_name, 'OUTPUT'] = _exc_info\n",
    "    return _METHOD_ARRAY_DICT\n",
    "\n",
    "\n",
    "COMBINATIONS = [f'{d}_{c}_{b}_{a}' for d in GOOD_OR_BAD_X for c in GOOD_OR_BAD_y for b in DTYPES for a in TYPES]\n",
    "METHOD_ARRAY_DICT = {k:pd.DataFrame(index=METHOD_NAMES, columns=['OUTPUT'], dtype=object) for k in COMBINATIONS}\n",
    "\n",
    "ctr = 0\n",
    "for good_or_bad_x in GOOD_OR_BAD_X:\n",
    "    for good_or_bad_y in GOOD_OR_BAD_y: \n",
    "        for _dtype in DTYPES:\n",
    "            for _gscv_type in TYPES:\n",
    "                ctr += 1\n",
    "                trial = f'{good_or_bad_x}_{good_or_bad_y}_{_dtype}_{_gscv_type}'\n",
    "\n",
    "                print(f'Running {ctr} of {len(COMBINATIONS)}... {trial}')\n",
    "\n",
    "                test_cls = init_gscv(SklearnLogistic, DaskLogistic, _gscv_type)\n",
    "\n",
    "                if _dtype == 'array':\n",
    "                    if 'dask' in _gscv_type:\n",
    "                        base_y = good_da_y\n",
    "                        if 'good' in good_or_bad_y: _y = good_da_y\n",
    "                        elif 'bad_features' in good_or_bad_y: _y = bad_features_da_y\n",
    "                        elif 'bad_classes' in good_or_bad_y: _y = bad_classes_da_y\n",
    "                        else: raise Exception(f\"good_or_bad_y logic is failing\")\n",
    "                        base_X = good_da_X\n",
    "                        if 'good' in good_or_bad_x: _X = good_da_X\n",
    "                        elif 'bad' in good_or_bad_x: _X = bad_da_X\n",
    "                        else: raise Exception(f\"good_or_bad_x logic is failing\")\n",
    "                    elif 'sklearn' in _gscv_type:\n",
    "                        base_y = good_np_y\n",
    "                        if 'good' in good_or_bad_y: _y = good_np_y\n",
    "                        elif 'bad_features' in good_or_bad_y: _y = bad_features_np_y\n",
    "                        elif 'bad_classes' in good_or_bad_y: _y = bad_classes_np_y\n",
    "                        else: raise Exception(f\"good_or_bad_y logic is failing\")                        \n",
    "                        base_X = good_np_X\n",
    "                        if 'good' in good_or_bad_x: _X = good_np_X\n",
    "                        elif 'bad' in good_or_bad_x: _X = bad_np_X\n",
    "                        else: raise Exception(f\"good_or_bad_x logic is failing\")\n",
    "                    else: raise Exception(f\"_gscv_type logic is failing\")\n",
    "                elif _dtype == 'dataframe':\n",
    "                    if 'dask' in _gscv_type:\n",
    "                        base_y = good_np_y    #good_ddf_y  UNPREDICABLE BEHAVIOR PASSING y AS DF TO DASK Logistic/GridSearch\n",
    "                        if 'good' in good_or_bad_y: _y = good_ddf_y\n",
    "                        elif 'bad_features' in good_or_bad_y: _y = bad_features_ddf_y\n",
    "                        elif 'bad_classes' in good_or_bad_y: _y = bad_classes_ddf_y\n",
    "                        else: raise Exception(f\"good_or_bad_y logic is failing\")\n",
    "                        base_X = good_ddf_X\n",
    "                        if 'good' in good_or_bad_x: _X = good_ddf_X\n",
    "                        elif 'bad' in good_or_bad_x: _X = bad_ddf_X\n",
    "                        else: raise Exception(f\"good_or_bad_x logic is failing\")\n",
    "                    elif 'sklearn' in _gscv_type:\n",
    "                        base_y = good_pd_y\n",
    "                        if 'good' in good_or_bad_y: _y = good_pd_y\n",
    "                        elif 'bad_features' in good_or_bad_y: _y = bad_features_pd_y\n",
    "                        elif 'bad_classes' in good_or_bad_y: _y = bad_classes_pd_y\n",
    "                        else: raise Exception(f\"good_or_bad_y logic is failing\")\n",
    "                        base_X = good_pd_X\n",
    "                        if 'good' in good_or_bad_x: _X = good_pd_X\n",
    "                        elif 'bad' in good_or_bad_x: _X = bad_pd_X\n",
    "                        else: raise Exception(f\"good_or_bad_x logic is failing\")\n",
    "                    else: raise Exception(f\"_gscv_type logic is failing\")\n",
    "                else: raise Exception(f\"_dtype logic is failing\")\n",
    "\n",
    "                \n",
    "                try: \n",
    "                    test_cls.fit(base_X, base_y)\n",
    "                except TypeError as e:\n",
    "                    for _m in METHOD_NAMES:\n",
    "                        METHOD_ARRAY_DICT[trial].loc[_m, 'OUTPUT'] = e\n",
    "                    del test_cls, base_X, base_y\n",
    "                    continue\n",
    "                except Exception as e2:\n",
    "                    print(f\"\\033[91mExcepted for a reason other than dask.dataframe into dask logistic TypeError\\033[0m\")\n",
    "                    raise Exception(e2)\n",
    "\n",
    "\n",
    "                del base_X, base_y\n",
    "            \n",
    "\n",
    "                try:\n",
    "                    __ = test_cls.score(_X, _y)\n",
    "                    METHOD_ARRAY_DICT = method_output_try_handler(trial, 'score', __, METHOD_ARRAY_DICT)\n",
    "                except:\n",
    "                    METHOD_ARRAY_DICT = method_output_except_handler(trial, 'score', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "    \n",
    "    \n",
    "                # REFERENCE ATTRS #################################################################################################\n",
    "                try:\n",
    "                    __ = test_cls.n_features_in_\n",
    "                    METHOD_ARRAY_DICT = method_output_try_handler(trial, 'n_features_in_', __, METHOD_ARRAY_DICT)\n",
    "                except:\n",
    "                    METHOD_ARRAY_DICT = method_output_except_handler(trial, 'n_features_in_', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "                \n",
    "                try:\n",
    "                    __ = test_cls.feature_names_in_\n",
    "                    METHOD_ARRAY_DICT = method_output_try_handler(trial, 'feature_names_in_', __, METHOD_ARRAY_DICT)\n",
    "                except:\n",
    "                    METHOD_ARRAY_DICT = method_output_except_handler(trial, 'feature_names_in_', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "    \n",
    "                try:\n",
    "                    __ = test_cls.classes_\n",
    "                    METHOD_ARRAY_DICT = method_output_try_handler(trial, 'classes_', __, METHOD_ARRAY_DICT)\n",
    "                except:\n",
    "                    METHOD_ARRAY_DICT = method_output_except_handler(trial, 'classes_', sys.exc_info()[1], METHOD_ARRAY_DICT)\n",
    "\n",
    "\n",
    "\n",
    "SINGLE_DF = pd.DataFrame(index=METHOD_NAMES, columns=list(METHOD_ARRAY_DICT.keys()), dtype='<U100').fillna('-')\n",
    "for _key, DATA_DF in METHOD_ARRAY_DICT.items():\n",
    "    SINGLE_DF.loc[:, _key] = DATA_DF.to_numpy().ravel()\n",
    "\n",
    "SINGLE_DF = SINGLE_DF.drop(['decision_function','inverse_transform','predict','predict_log_proba','predict_proba',\n",
    "                            'score_samples','transform'], inplace=False)\n",
    "\n",
    "SINGLE_DF = SINGLE_DF.T\n",
    "\n",
    "if os.name =='posix': method_path = rf'/home/bear/Desktop/gscv_bad_X_bad_y_comparison_dump__score.ods'\n",
    "elif os.name=='nt': method_path = rf'c:\\users\\bill\\desktop\\gscv_bad_X_bad_y_comparison_dump__score.csv'\n",
    "\n",
    "SINGLE_DF.to_csv(method_path, index=True)\n",
    "\n",
    "# DONE\n",
    "\n",
    "\n",
    "\n",
    "_rows, _cols = 20, 5\n",
    "DATA = np.random.randint(0,10,(_rows,_cols))\n",
    "Y = np.random.randint(0,2,_rows)\n",
    "\n",
    "# AS ARRAY\n",
    "sk_arr_X = DATA\n",
    "# bad_sk_arr_X = np.random.randint(0,10,(_rows,2*_cols))\n",
    "sk_arr_y = Y\n",
    "\n",
    "# AS DF\n",
    "sk_df_X = pd.DataFrame(data=DATA)#, columns=list(string.ascii_lowercase[:_cols]))\n",
    "sk_df_y = pd.Series(Y).to_frame()\n",
    "\n",
    "\n",
    "# AS ARRAY\n",
    "da_arr_X = da.array(sk_arr_X)   # chunks=(_rows//2, _cols)\n",
    "# bad_da_arr_X = da.array(bad_sk_arr_X)\n",
    "da_arr_y = da.array(Y)\n",
    "\n",
    "# AS DF\n",
    "da_df_X = ddf.from_pandas(sk_df_X, chunksize=_rows)\n",
    "da_df_y = ddf.from_pandas(sk_df_y, npartitions=1)\n",
    "\n",
    "clf = sklearn_Logistic()\n",
    "\n",
    "clf.fit(sk_df_X, sk_df_y)\n",
    "\n",
    "\n",
    "# clf.feature_names_in_\n",
    "\n",
    "\n",
    "\n",
    "SklearnLogistic = sklearn_Logistic(fit_intercept=True)\n",
    "\n",
    "TEST_NP_GSCV = sklearn_GridSearchCV(\n",
    "                                     SklearnLogistic,\n",
    "                                     {'C':np.logspace(-3,3,7)},\n",
    "                                     scoring=['balanced_accuracy','accuracy'],\n",
    "                                     refit='balanced_accuracy',\n",
    "                                     error_score='raise',\n",
    ")\n",
    "\n",
    "TEST_NP_GSCV.fit(sk_df_X, sk_df_y)\n",
    "# TEST_NP_GSCV.predict_proba(sk_df_X)\n",
    "\n",
    "# TEST_NP_GSCV.feature_names_in_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf = dask_Logistic(fit_intercept=False)\n",
    "\n",
    "clf.fit(da_df_X, da_df_y)\n",
    "\n",
    "# clf.features_names_in_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DaskLogistic = dask_Logistic(fit_intercept=False)\n",
    "\n",
    "TEST_DA_GSCV = dask_GridSearchCV(\n",
    "                                 DaskLogistic,\n",
    "                                 {'C':np.logspace(-3,3,7)},\n",
    "                                 scoring=['balanced_accuracy','accuracy'],\n",
    "                                 refit='balanced_accuracy',\n",
    "                                 error_score='raise',\n",
    ")\n",
    "\n",
    "TEST_DA_GSCV.fit(da_arr_X, da_arr_y)\n",
    "TEST_DA_GSCV.predict_proba(da_arr_X).compute()\n",
    "\n",
    "# TEST_DA_GSCV.feature_names_in_\n",
    "\n",
    "\n",
    "TEST_DA_GSCV.score(da_arr_X, da_arr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87483a33-a003-4a19-9f67-771e5ed5c8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee1680-aa4b-4ed0-9bba-50e7e8c4e1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94131254-9acc-4da5-a76e-90fcbac56ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
